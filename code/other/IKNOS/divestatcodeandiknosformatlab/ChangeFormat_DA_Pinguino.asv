%output=ChangeFormat_DA_Pinguino(filename,Start,End,TOPPID)
%
% Function to prepare csv file, fix errors, and run dive analysis on emperor penguin TDR data. 
%
% Created by: Rachel Holser (rholser@ucsc.edu)
% Created on: 02-Apr-2023
% Modified from Change_Format_DA_V4_2
%
% Requires functions: iknos_da
%                    DA_data_compiler_V4
%                    yt_findclosest_RRH
%                    resolution_DepthRes
%
% Update Log:
% 

function ChangeFormat_DA_Pinguino(filename)
%% Step 1: load csv of TDR data
    data=readtable(filename,'HeaderLines',0,'ReadVariableNames',true);

    %Penguin 16 and 24 had time adjustments and columns differ
    if strcmp(filename,'22_temp_pressure_time_corrected_24.csv')==1
        data(:, [18, 19]) = [];
    end

    %Test for normal headers.  If Depth header is missing, re-imports file with no headers and assigns them.
    if isempty(find(strcmp('Depth', data.Properties.VariableNames))>0)
        data=readtable(filename,'HeaderLines',0,'ReadVariableNames',false);
        data.Properties.VariableNames(1)={'Time'};
        data.Properties.VariableNames(2)={'Depth'};
%         data(1,:)=[]; %remove top row - often has faulty time format when no headers
    end

%% Step 2: remove rows with depth issues
    %Step 2.1: remove rows with NaNs (often present in row with duplicate time stamp)
    data(isnan(data.Depth),:)=[];
    
    data.Depth=round(data.Depth,1);

    
%% Step 3: date conversions
    %Step 3.1: Convert to datetime then parse out time into separate columns using datevec
    try
        data.Time=datetime(data.Date+data.Time,'Format','yyyy-MM-dd HH:mm:ss.SSS');
    end

    try
        data.Time=datetime(data.Date+data.Time,'Format','yyyy-MM-dd HH:mm:ss');
    end

    if sum(strcmp(data.Properties.VariableNames,'Year'))>0
    else
        try
            data.Time=datetime(data.Time,'InputFormat','yyyy-MM-dd''T''HH:mm:ss.SSS''Z''');
        end
    end

    try
        data.Time=datetime(data.Timestamp);
    end

    try
        data.Time=datetime(string(data.Timestamp), 'InputFormat', 'yyyy-MM-dd''T''HH:mm:ss.SSS''Z''');
    end

    try
        data.Time=datetime(string(data.Timestamp), 'InputFormat', 'yyyy-MM-dd''T''HH:mm:ss''Z''');
    end

    try
        data.Time=datetime(data.Time,'InputFormat','yyyy-MM-dd''T''HH:mm:ss''Z''','TimeZone','UTC');
    end

    %look for timestamps that did not convert after all of the above
    %attempts (added for 22_GM23.csv which required manual datetime
    %interpolation and some values had extra decimal points).
    ind=find(isnat(data.Time));
    if size(ind,1)>0
        data.Time(ind)=datetime(string(data.Timestamp(ind)), 'InputFormat', 'yyyy-MM-dd''T''HH:mm:ss.SSS''Z''','TimeZone','UTC');
    end

    %after datetime conversions, create date vector
    % data.Time=dateshift(data.Time,'start','second');
    % [data.Year, data.Month, data.Day, data.Hour, data.Min, data.Sec]...
    %     =datevec(data.Time);

    % Convert datetime to posix time (seconds since 1970-01-01)
    posix_time = posixtime(data.Time);

    % Round to nearest second
    rounded_posix_time = round(posix_time);

    % Convert back to datetime
    data.Time = datetime(rounded_posix_time, 'ConvertFrom', 'posixtime');

    [data.Year, data.Month, data.Day, data.Hour, data.Min, data.Sec]...
        =datevec(data.Time);


    data = sortrows(data, 19);

%% Step 4: calculate sampling rate
    SamplingDiff=diff(data.Time);
    SamplingRate=seconds(round(mode(SamplingDiff)));

%% Step 5: Remove data with bad times (zero or negative sampling rates or NaT)
% NOTE: This will only remove SINGLE bad lines and will not deal with full time shifts.
    % OffTime_ind=find(SamplingDiff<=0);
    % data(OffTime_ind(1)-2:OffTime_ind(1)+2,:)  %% look at the rows above
    % and below the offtime, change ind as needed
    % OffTime_ind(:)=OffTime_ind(:)+1;
    % data(OffTime_ind,:)=[];
%     
    NaTTime_ind=find(isnat(data.Time));
    data(NaTTime_ind,:)=[];

    % %Penguin 19 2019 has special datetime needs
    % if sum(strcmp(data.TagID(1),'EP19_PEN19_EP9_B_S1'))>0
    %     data(data.Year==2020,:)=[];
    %     data(data.Year==2080,:)=[];
    % end

    % %Penguin 16 2022 has special datetime needs
    if sum(strcmp(data.TagID(1),'22_GM16_S1'))>0
        OffTime_ind=find(SamplingDiff<=0);
        OffTime_ind(:)=OffTime_ind(:)+1;
        data(OffTime_ind,:)=[];
        data = sortrows(data, 'Time');
        [~, dupidx] = unique(data.Time, 'stable');
        data = data(dupidx, :);
    end

    % Penguin 19 we have gone back and interpolated the timestamps so no
    % just need to run code for it similar to below as it also has 47 repeat times
    % due to rounding

    % %Penguin 19 2022 has special datetime needs
    if sum(strcmp(data.TagID(1),'22_GM19_S1'))>0
        data(data.Month< 11,:)=[];
        OffTime_ind=find(SamplingDiff<=0);
        OffTime_ind(:)=OffTime_ind(:)+1;
        data(OffTime_ind,:)=[];
        data = sortrows(data, 'Time');
        [~, dupidx] = unique(data.Time, 'stable');
        data = data(dupidx, :);
    end

    %Penguin 24 has repeat times
    if strcmp(filename,'22_temp_pressure_time_corrected_24.csv')==1
        OffTime_ind=find(SamplingDiff<=0);
        data(OffTime_ind,:)=[];
        data = sortrows(data, 'Time');
        [~, dupidx] = unique(data.Time, 'stable');
        data = data(dupidx, :);
    end

    if strcmp(filename,'EMPE_2019_CACR_Pen19_Axy9_fixed5_raw.csv')==1
        OffTime_ind=find(SamplingDiff<=0);
        data(OffTime_ind,:)=[];
    end

%% Step 6: generate variable string for iknos da and write to new .csv.
    
    [data_DA,DAstring]=DA_data_compiler_pinguino_RRH_TV4(data);
    writematrix(data_DA,[strtok(char(filename),'.') '_DAprep_full.csv']);
    fid=fopen([strtok(char(filename),'.') '_DAString.txt'],'wt');
    fprintf(fid,DAstring);
    fclose(fid);

%% Step 7: Depth resolution and MinMax detection
    DepthRes=resolution_DepthRes(data.Depth);

    %Step 7.1: detect if dive surface intervals have offset >10m.
    running_surface = movmin(data.Depth,hours(2),'SamplePoints',data.Time);
    [f,xi]=ecdf(running_surface); %figure; ecdf(running_surface,'Bounds','on');
    
    if abs(xi(3)-xi(2))>10 % if there's a large jump, might be due to surface spikes
        minsurface=xi(3);
    else
        minsurface=interp1(f,xi,0.05);
    end

    % run the following instead of the if statement above for second pass
    % ZOC
    % minsurface=interp1(f,xi,0.05);

%% Step 8: Run IKNOS DA - new ZocMinMax with DEFAULT ZOC params
% if strcmp(filename,'22_GM16.csv')~=1
%     if minsurface<-10
%         iknos_da([strtok(filename,'.') '_DAprep_full.csv'],DAstring,...
%             20/SamplingRate,3/DepthRes,20,'wantfile_yes','ZocWindow',1,...
%             'ZocMinMax',[minsurface-10,650]);
%     else
%         iknos_da([strtok(filename,'.') '_DAprep_full.csv'],DAstring,...
%             20/SamplingRate,3/DepthRes,20,'wantfile_yes','ZocWindow',1,...
%             'ZocMinMax',[-10,650]);
%     end
% end
% 
% if strcmp(filename,'22_GM16.csv')==1
%   if minsurface<-10
%         iknos_da([strtok(filename,'.') '_DAprep_full.csv'],DAstring,...
%             20/SamplingRate,3/DepthRes,20,'wantfile_yes','ZocWindow',1,...
%             'ZocWidthForMode',30,'ZocSurfWidth',10,'ZocDiveSurf',15,... 
%             'ZocMinMax',[minsurface-10,650]);
%     else
%         iknos_da([strtok(filename,'.') '_DAprep_full.csv'],DAstring,...
%             20/SamplingRate,3/DepthRes,20,'wantfile_yes','ZocWindow',1,...
%             'ZocWidthForMode',30,'ZocSurfWidth',10,'ZocDiveSurf',15,... 
%             'ZocMinMax',[-10,650]);
%     end
% end


    if minsurface<-10
        iknos_da([strtok(filename,'.') '_DAprep_full.csv'],DAstring,...
            20/SamplingRate,3/DepthRes,20,'wantfile_yes','ZocWindow',1/3,...
            'ZocWidthForMode',50,'ZocSurfWidth',25,'ZocDiveSurf',25,... 
            'ZocMinMax',[minsurface-10,650]);
    else
        iknos_da([strtok(filename,'.') '_DAprep_full.csv'],DAstring,...
            20/SamplingRate,3/DepthRes,20,'wantfile_yes','ZocWindow',1/3,...
            'ZocWidthForMode',50,'ZocSurfWidth',25,'ZocDiveSurf',25,...
            'ZocMinMax',[-10,650]);
    end


        % above need to add  'ZocWidthForMode',30,'ZocSurfWidth',10,'ZocDiveSurf',15,... 
        % just above the last line of each chunk for 2022 Tag 16 that had a lot of noise 
        % the mode is set number that calcs the mode in the upper portion
        % and the minimum depth within a temporal window; the surf width
        % is how deep want to define it - uses 10 * the dive resolution; zoc 
        % dive surf is looking both up and down insitead of just down (but
        % same principle as before)

        % trying this for all noisey ones
            % 'ZocWidthForMode',50,'ZocSurfWidth',25,'ZocDiveSurf',25,... 

%% Step 9: Plot and save QC figs

    % Load rawzoc data and divestat files
    rawzocdatafile=dir([strtok(char(filename),'.') '_DAprep_full_iknos_rawzoc_data.csv']);
    rawzocdata=readtable(rawzocdatafile.name,'HeaderLines',23,'ReadVariableNames',true);
    rawzocdata.Time=datetime(rawzocdata.time,'ConvertFrom','datenum');
    
    DiveStatfile=dir([strtok(char(filename),'.') '_DAprep_full_iknos_DiveStat.csv']);
    DiveStat=readtable(DiveStatfile.name,'HeaderLines',23,'ReadVariableNames',true);
    DiveStat.Time=datetime(DiveStat.Year,DiveStat.Month,DiveStat.Day,DiveStat.Hour,DiveStat.Min,DiveStat.Sec);
    
    %plot raw and zoc'd data and indicate all dive start and ends from divestat
    figure(1);
    plot(rawzocdata.Time,rawzocdata.depth);
    hold on; set(gca,'YDir','reverse');
    plot(rawzocdata.Time,rawzocdata.CorrectedDepth,'b');
    scatter(DiveStat.Time,zeros(size(DiveStat,1),1),[],'go');
    scatter(DiveStat.Time+seconds(DiveStat.Dduration),zeros(size(DiveStat,1),1),[],'ro');
    text(DiveStat.Time,DiveStat.Maxdepth,num2str(DiveStat.DiveNumber),'Color','b');
    legend({'raw','zoc','Start dive','End dive'});
    title(['Raw vs ZOC: ' strtok(char(filename),'.')]);
    savefig([strtok(char(filename),'.') '_Raw_ZOC.fig']);
    close;
    
    clear bad_data Cut_Ind ind_bad1 ind1 ind2 OffTime_ind NaTTime_ind offset compress Cut minsurface
end
